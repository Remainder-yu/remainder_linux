# 微内核架构

## futex锁机制实现--用户态锁实现
### 难点
futex：整个实现调用链设计硬件原子\内核并发、调度器、内核锁实现机制（中断锁，关调度等）等。
只要一个环节与边界条件没对齐，就会出现丢唤醒、优先级反转等。这才是 futex 被称为“用户态一行代码，内核态十年补丁”的原因。

用户态对共享变量的写入，必须让内核在“检查该变量”与“把线程挂起”这两个动作之间看得见，否则就永远睡死。

### 丢唤醒
弱内存模型下，user 与 kernel 的内存序必须配对：
Linux 用 set_user() 里隐式 DMB，Fuchsia 要在 zx_futex_wait 入口显式 atomic_thread_fence(memory_order_seq_cst)，否则 *uaddr 检查与真正挂起之间可能重入，造成**“丢唤醒”**。

用户态对共享变量的写入，必须让内核再“检查该变量”与线程挂起这两个动作之间看得见，否则就会永远睡死。
五fence的坏序列（若内存模型CPU允许重排）
```cpp
// 用户态解锁路径
unlock() {
    lock->uaddr = 0;            // ① store 0
    // 没有内存屏障
}

// 用户态加锁路径
lock() {
    if (CAS(&lock->uaddr, 0, 1)) return;   // ② fast-path 成功
    // slow path
    for (;;) {
        int v = lock->uaddr;               // ③ load 当前值
        if (v != 0 &&
            syscall(SYS_futex, &lock->uaddr, FUTEX_WAIT, v, NULL) == 0)
            break;
    }
}
```
cpu允许把1的store延迟到之后执行。出现以下时许：
```shell
CPU-0 解锁线程                  CPU-1 加锁线程
─────────────────              ─────────────────
① store 0 进入 ST buffer
                               ③ load uaddr 拿到 1
                               进入内核：
                               ├─ 内核读 *uaddr 得到 1
                               ├─ 校验通过
                               ├─ 把线程设为 TASK_INTERRUPTIBLE
                               ├─ 调度走 —— 此刻**真正睡眠**
② ST buffer 终于刷到 cache
                               → 解锁线程的 0 才被别的 CPU 看见
                               → 没人再 wake，永远睡死
```
这就是典型的（Lost wake-up）内存检查值与挂起之间，用户态的写入被延迟或未完成，就被调度切换，导致检查通过但实际已生效，没人再唤醒，导致线程回收时，触发未被唤醒的线程死等待，系统崩溃。
所以保证内核与用户态的执行内存序对齐，让写入-刷回-检查-挂起按照顺序执行。

根本原因就是：弱内存模型 CPU 允许 store 延迟、load 提前，检查时值是对的，但真正的 0 还在 Store Buffer里，内核一挂起就永远没人再唤醒——睡死线程就是这么来的。

保证拿锁的线程唤醒时，在内核调用过程，整个过程不被调度，也就是睡眠路径根本不会被走到，丢唤醒自然消失。

### 扩展
CAS机制与CMP原子比较修改：读-改-写一次性原子决策，成功修改为期望新状态（值），失败，则需要重新再进行一次比较修改。
CAS（Compare-And-Swap，比较并交换）是原子指令的祖宗，也是整个无锁（lock-free）世界的地基。

ARMv8相关指令集：
```shell
LL/SC 实现（A64）
┌──────────────┐          ┌──────────────┐
│  LDAXR  x0,[x1]   ←─① 读独占   │  把 *addr 载入 x0，标记物理地址“独占”
│  CMP    x0,old    ←─② 比较     │  是否等于预期？
│  B.NE   fail                     │  不等直接失败
│  STLXR  w2,new,[x1] ←─③ 写独占 │  相等则尝试写入新值
│  CBNZ   w2,retry                 │  写独占失败（w2=1）重试
│  CLREX                           │  成功清除独占标记
└──────────────┘
```

## 协议栈优化

微内核涉及：内核、网卡驱动、网络协议栈、POSIX适配层等。
网络驱动通过内核IPC-FIFO进行数据转发至协议栈，协议栈通过内核IPC-socket传输给POSIX适配层，然后用户系统调用业务。这个过程中，协议栈本身还有数据包的封装解析、一层一层的向上转发。
缺点：调用链过长，需要通过iperf以及专用的打点工具分析链路中各个数据流转点的性能损耗。

### 性能瓶颈点
协议栈通过IPC-FIFO从驱动拿到数据包，再分发给网络层处理之前，有个较长的处理流程：FIFO收包->数据包拷贝封装->抓包转发->二层解析->桥转发等。
### 优化点
##### 批处理
所以有必要对其进行批量化处理：批量从IPC-FIFO取包，批量封装以及桥转发。利用协议栈的数据处理能力，扩大多条流的同时处理，扩大缓冲区数据，处理数据包多条，达到批量处理。
##### 同步IO进行异步改造
这里的IO主要是POSIX适配层与协议栈之间的控制域、数据域IO交互。在之前的架构中，控制域和数据域IO都是同步的，这样会导致反复的二次调用IPC来判断状态，多个IO控制层之间硬拷贝数据。由于IPC-SOCKET是非阻塞的，所以需要借用外部的waiter机制来进行阻塞读写，对IO进行异步改造就是引入一层异步IO，代替之前的同步IO封装层，由后台异步任务维护连接状态以及缓存数据。
协议栈升级
在go语言协议栈内部分段对带宽进行测试，发现在IP层开始，带宽性能开始出现大幅损耗。IP层主要作用包括寻址、路由选择、分片和重组、以及ICMP处理等，而ZEOS系统对golang语言的性能上存在瓶颈，考虑将协议栈升级到rust语言的netstack。

### iperf3测试工具原理
测试原理：
* 采用客户端 - 服务器（C/S）架构，需先启动服务端监听端口，客户端主动发起连接。
* 测试时客户端按配置（如带宽上限、数据块大小）向服务端持续发送 TCP/UDP 数据包。
* 服务端接收数据后，计算传输速率、丢包率、延迟等指标，与客户端交互校验结果，最终输出统计报告。

网络带宽的核心指标：
. 关键核心指标
1. 吞吐量（Throughput）：实际每秒能传输的有效数据量（单位 Mbps/Gbps），是最核心的带宽指标，反映网络真实承载能力。
2. 带宽上限（Bandwidth）：网络理论支持的最大传输速率（如千兆网标称 1000Mbps），实际吞吐量会因损耗低于该值。
3. 丢包率（Packet Loss）：传输中丢失的数据包占总发送数的比例（UDP 测试重点），丢包率过高会导致数据重传、延迟增加。
4. 延迟（Latency）：数据包从客户端发送到服务端接收的总时间（单位 ms），含传输延迟、处理延迟等，影响实时性应用。
5. 抖动（Jitter）：延迟的波动范围（单位 ms），抖动大对语音、视频等实时业务影响显著。



## POSIX适配层

让普通 Linux 二进制（ELF）不用修改、不用重编译，就能直接在 Fuchsia 上跑起来，并且“看起来”自己仍然跑在 Linux 内核里。

```shell
┌─────────────────────────────────────────┐
│  Linux 应用 (nginx, Redis, Android APK) │
│  ELF .so 依赖 glibc/musl                │
└────────────────┬────────────────────────┘
                 │ 系统调用 int 0x80 / svc #0
┌────────────────▼────────────────────────┐
│           Starnix 层                    │
│  ┌-------------------------------------┐ │
│  │ 1. syscall 分派 (linux_syscall.cpp)│ │  ← 把 Linux 编号转成内部 op
│  │ 2. 对象语义层                        │ │
│  │    · task → zx_process + zx_thread  │ │
│  │    · fd   → zx_handle (socket, vmo) │ │
│  │    · epoll→ zx_port                   │ │
│  │    · pipe → zx_socket(Stream)        │ │
│  │    · signalfd → zx_port + exception  │ │
│  │ 3. /proc, /sys, tmpfs, devpts        │ │  ← 虚拟文件系统
│  │ 4. 信号、ptrace、seccomp、futex       │ │
│  └-------------------------------------┘ │
└────────────────┬────────────────────────┘
                 │ zx 系统调用
┌────────────────▼────────────────────────┐
│           Zircon 微内核                 │
│  process, thread, vm_object, channel,   │
│  socket, port, interrupt, timer         │
└─────────────────────────────────────────┘

```

从 Linux 用户态 svc #0 → 内核 el1_sync → Starnix syscall 分派 → 返回 eret。

```shell
Linux 64-bit app (EL0)
┌──────────────────────────────┐
│ mov     x8, #83              │  // sys_mmap
│ svc     #0                   │  // 64-bit linux syscall
└────┬─────────────────────────┘
     V
CPU 同步异常向量 ───────────────┐
VBAR_EL1 + 0x400 (el0_sync)     │
┌─► kernel/arch/arm64/el0_sync.S│
│   kernel_exit 保存 pt_regs     │
│   stp x0, x1, [sp, #16 * 0]    │
│   mov x0, sp                   │  // pt_regs *
│   bl  starnix_el0_handler      │
└────┬───────────────────────────┘
     V
starnix/syscall/starnix_el0_handler()
┌────────────────────────────────────┐
│ regs->orig_x8 = x8                 │  // syscall nr
│ regs->x0 ... x5 = 参数              │
│ if (regs->x8 < 512)                │
│     ret = linux_syscall_table[x8](regs); │
│ else                               │
│     ret = -ENOSYS;                 │
│ regs->x0 = ret;                    │  // 返回值写回
│ kernel_exit 0, eret                │
└────┬───────────────────────────────┘
     V
eret // ELR_EL1 = regs->pc, SPSR_EL1 = 0x0 (EL0t)
回到用户态 EL0
```
restricted模式：
线程跑在EL1，但是看不见内核，只能看到该线程运行的资源。
```cpp
loader.restricted_elf_load()
├─ zx_restricted_bind(handle, entry, restricted_vmo_list[])
│  ├─ aspace_create_restricted()   // 新建“小页表”
│  │   仅映射：ELF、栈、vdso、restricted_vmo_list
│  ├─ thread_restricted_enter()
│  │   t->restricted_flag = 1
│  │   t->elr_el1 = entry
│  │   t->spsr_el1 = 0x205 (EL1t, SP0)
│  │   ttbr0_el1 = restricted_ttbr0  // 只有白名单物理页
│  │   ttbr1_el1 = 0                  // 不映射内核
└─ 首次调度 → eret 到 EL1 入口
```
结果：
PC 运行在 EL1，但页表里 没有 kernel text、没有 kstack、没有外设；
任何访问 0xffff... 内核地址 → stage-1 页表走空 → EL1 同步异常 → kill。

# Linux


## yocto构建

管理源代码、构建工程、添加组件、定制化裁剪。

## RT补丁

RT 补丁（PREEMPT_RT）的核心作用：把 Linux 从“通用分时操作系统”变成“硬实时操作系统”。让关键任务在严格时间内完成响应，不会因为内核不可抢占、关中断、锁竞争而掉链子。

### RT修改了什么

| 场景         | 原版 Linux                           | PREEMPT\_RT 后                            | 效果                              |
| ---------- | ---------------------------------- | ---------------------------------------- | ------------------------------- |
| **关中断临界区** | `local_irq_disable()` 屏蔽中断 100 ms+ | 把 **irq off** 变成 **irq thread**（线程化中断）   | 中断随时可响应，**延迟 < 10 µs**          |
| **自旋锁**    | `raw_spinlock` 忙等 + 关抢占            | 变成 **sleepable rt\_mutex**，可调度让出 CPU     | 高优先级任务可**强制抢占**持锁低优先级任务         |
| **定时器**    | 基于 **tick**（HZ）                    | 高精度 **hrtimer** + **NO\_HZ\_FULL**       | 周期抖动从毫秒级降到 **< 20 µs**          |
| **调度延迟**   | 内核态不可抢占（临界区、调度关闭）                  | 打开 **CONFIG\_PREEMPT\_RT** 后，**几乎全程可抢占** | 最坏调度延迟 **< 100 µs**（x86\_64 实测） |

二、RT 补丁 5 大关键技术点
中断线程化（threaded IRQ）
所有中断下半部变成 可调度线程，拥有 实时优先级 50-80，高优先级任务可随时抢占。
自旋锁 → rt_mutex
把 spinlock_t 内部换成 rt_mutex，支持优先级继承（PI），避免优先级反转。
关抢占区 → 可抢占
原版 preempt_disable() 区在 RT 下变成 “可抢占临界区”，通过 per-CPU 计数器 + rt_mutex 实现。
高精度时钟（hrtimer）
取代传统 jiffies，支持 纳秒级分辨率，配合 NO_HZ_FULL 消除周期时钟中断。
内存管理实时优化
把 mlockall() 和 vmalloc 的关中断区拆分，页面故障路径可抢占，避免 page fault 延迟抖动。

### 各修改方案原理

#### 硬中断线程化

#### Mutex优先级继承
为了防止发生优先级反转，Mutex实现采用了rt_mutex的实现，具有优先级集成，同时对锁流程进行实时性优化改造。

优先级反转发生场景
1. 低优先级任务A获取锁资源
2. 中优先级任务B执行CPU密集型任务，抢占低优先级任务A
3. 高优先级任务C试图获取低优先级任务A持有的锁，但由于中优先级任务B抢占了低优先级任务A而阻塞
这种优先级反转会无限期延迟高优先级任务。



## systemd及启动优化
systemd服务本身框架？


## BSP集成及烧写


## 安全启动-启动流程

# Hypervisor

## armv8虚拟化

## 域间通信方案

## 音视频实现方案


# 个人优势
1. 学历背景及实验室：
2. 工作平台及项目经历：多个类型OS开发经验，微内核 -> linux -> hypervisor跨域融合复杂虚拟化架构
3. 行业标准和开发流程：
4. 操作系统基础知识：
5. arm硬件架构知识，硬件辅助虚拟化，知道各虚拟化方案的优缺点。
6. 技术前沿了解：
7. 工作中不仅注重研发功能本身，包括功能
8. 基于该背景，对于上层业务功能开发及底层开发都有整体系统框架的支撑
9. 故障定位及分析，会思考如何提高开发效率，下次针对同等问题进行通用方案解决

